{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_15952\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.uint8(255)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.13066062)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dense name=dense_23, built=True>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05551663,  0.06676759,  0.06151071, ..., -0.04397593,\n",
       "         0.04186476,  0.03564633],\n",
       "       [ 0.05210023,  0.03642846, -0.0457    , ...,  0.04840887,\n",
       "        -0.01530011, -0.00686113],\n",
       "       [ 0.00966153,  0.02735929,  0.05903132, ..., -0.01683571,\n",
       "        -0.02304412,  0.03871221],\n",
       "       ...,\n",
       "       [-0.01225122,  0.03767928,  0.005555  , ...,  0.05223209,\n",
       "        -0.05372532, -0.02241868],\n",
       "       [ 0.00920855, -0.07201785,  0.0390292 , ...,  0.02117398,\n",
       "        -0.06117536,  0.0038506 ],\n",
       "       [ 0.03984117, -0.0683577 ,  0.03140345, ...,  0.00348397,\n",
       "         0.0165141 , -0.03767277]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"], \n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "40000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.5203 - loss: 1.6981 - val_accuracy: 0.8742 - val_loss: 0.5644\n",
      "Epoch 2/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8673 - loss: 0.5418 - val_accuracy: 0.8996 - val_loss: 0.3791\n",
      "Epoch 3/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8924 - loss: 0.3983 - val_accuracy: 0.9105 - val_loss: 0.3224\n",
      "Epoch 4/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9059 - loss: 0.3411 - val_accuracy: 0.9176 - val_loss: 0.2944\n",
      "Epoch 5/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9111 - loss: 0.3158 - val_accuracy: 0.9216 - val_loss: 0.2761\n",
      "Epoch 6/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9155 - loss: 0.2975 - val_accuracy: 0.9272 - val_loss: 0.2584\n",
      "Epoch 7/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9238 - loss: 0.2710 - val_accuracy: 0.9311 - val_loss: 0.2469\n",
      "Epoch 8/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.2591 - val_accuracy: 0.9334 - val_loss: 0.2362\n",
      "Epoch 9/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9295 - loss: 0.2514 - val_accuracy: 0.9361 - val_loss: 0.2269\n",
      "Epoch 10/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9324 - loss: 0.2389 - val_accuracy: 0.9373 - val_loss: 0.2195\n",
      "Epoch 11/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9341 - loss: 0.2301 - val_accuracy: 0.9396 - val_loss: 0.2110\n",
      "Epoch 12/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9374 - loss: 0.2222 - val_accuracy: 0.9431 - val_loss: 0.2043\n",
      "Epoch 13/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9399 - loss: 0.2088 - val_accuracy: 0.9443 - val_loss: 0.1990\n",
      "Epoch 14/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9425 - loss: 0.2034 - val_accuracy: 0.9474 - val_loss: 0.1928\n",
      "Epoch 15/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9447 - loss: 0.1963 - val_accuracy: 0.9475 - val_loss: 0.1881\n",
      "Epoch 16/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9459 - loss: 0.1897 - val_accuracy: 0.9495 - val_loss: 0.1833\n",
      "Epoch 17/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1852 - val_accuracy: 0.9528 - val_loss: 0.1793\n",
      "Epoch 18/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9488 - loss: 0.1773 - val_accuracy: 0.9531 - val_loss: 0.1754\n",
      "Epoch 19/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9512 - loss: 0.1711 - val_accuracy: 0.9542 - val_loss: 0.1714\n",
      "Epoch 20/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9531 - loss: 0.1646 - val_accuracy: 0.9552 - val_loss: 0.1667\n",
      "Epoch 21/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9535 - loss: 0.1622 - val_accuracy: 0.9556 - val_loss: 0.1625\n",
      "Epoch 22/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9550 - loss: 0.1606 - val_accuracy: 0.9579 - val_loss: 0.1585\n",
      "Epoch 23/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9556 - loss: 0.1568 - val_accuracy: 0.9565 - val_loss: 0.1559\n",
      "Epoch 24/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9573 - loss: 0.1490 - val_accuracy: 0.9580 - val_loss: 0.1529\n",
      "Epoch 25/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9581 - loss: 0.1494 - val_accuracy: 0.9583 - val_loss: 0.1510\n",
      "Epoch 26/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9602 - loss: 0.1435 - val_accuracy: 0.9587 - val_loss: 0.1462\n",
      "Epoch 27/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9609 - loss: 0.1376 - val_accuracy: 0.9600 - val_loss: 0.1449\n",
      "Epoch 28/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9605 - loss: 0.1377 - val_accuracy: 0.9601 - val_loss: 0.1413\n",
      "Epoch 29/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9606 - loss: 0.1389 - val_accuracy: 0.9610 - val_loss: 0.1397\n",
      "Epoch 30/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9642 - loss: 0.1276 - val_accuracy: 0.9612 - val_loss: 0.1375\n",
      "Epoch 31/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9657 - loss: 0.1247 - val_accuracy: 0.9613 - val_loss: 0.1371\n",
      "Epoch 32/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.9639 - loss: 0.1256 - val_accuracy: 0.9627 - val_loss: 0.1335\n",
      "Epoch 33/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9654 - loss: 0.1245 - val_accuracy: 0.9627 - val_loss: 0.1329\n",
      "Epoch 34/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9667 - loss: 0.1175 - val_accuracy: 0.9635 - val_loss: 0.1296\n",
      "Epoch 35/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9675 - loss: 0.1147 - val_accuracy: 0.9638 - val_loss: 0.1274\n",
      "Epoch 36/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.1137 - val_accuracy: 0.9644 - val_loss: 0.1274\n",
      "Epoch 37/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9687 - loss: 0.1111 - val_accuracy: 0.9652 - val_loss: 0.1244\n",
      "Epoch 38/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9695 - loss: 0.1091 - val_accuracy: 0.9656 - val_loss: 0.1237\n",
      "Epoch 39/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9713 - loss: 0.1029 - val_accuracy: 0.9650 - val_loss: 0.1238\n",
      "Epoch 40/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9715 - loss: 0.1023 - val_accuracy: 0.9656 - val_loss: 0.1202\n",
      "Epoch 41/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9721 - loss: 0.1002 - val_accuracy: 0.9667 - val_loss: 0.1193\n",
      "Epoch 42/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9713 - loss: 0.1027 - val_accuracy: 0.9667 - val_loss: 0.1178\n",
      "Epoch 43/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0970 - val_accuracy: 0.9672 - val_loss: 0.1160\n",
      "Epoch 44/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9745 - loss: 0.0931 - val_accuracy: 0.9679 - val_loss: 0.1143\n",
      "Epoch 45/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0954 - val_accuracy: 0.9676 - val_loss: 0.1134\n",
      "Epoch 46/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9736 - loss: 0.0952 - val_accuracy: 0.9676 - val_loss: 0.1126\n",
      "Epoch 47/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9750 - loss: 0.0895 - val_accuracy: 0.9680 - val_loss: 0.1116\n",
      "Epoch 48/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0868 - val_accuracy: 0.9690 - val_loss: 0.1106\n",
      "Epoch 49/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0858 - val_accuracy: 0.9695 - val_loss: 0.1093\n",
      "Epoch 50/50\n",
      "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9762 - loss: 0.0860 - val_accuracy: 0.9696 - val_loss: 0.1081\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9760 - loss: 0.0856 - val_accuracy: 0.9696 - val_loss: 0.1071\n",
      "Epoch 2/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.0832 - val_accuracy: 0.9683 - val_loss: 0.1076\n",
      "Epoch 3/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9783 - loss: 0.0801 - val_accuracy: 0.9711 - val_loss: 0.1048\n",
      "Epoch 4/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9794 - loss: 0.0753 - val_accuracy: 0.9705 - val_loss: 0.1050\n",
      "Epoch 5/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9806 - loss: 0.0722 - val_accuracy: 0.9683 - val_loss: 0.1070\n",
      "Epoch 6/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9809 - loss: 0.0711 - val_accuracy: 0.9723 - val_loss: 0.1032\n",
      "Epoch 7/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0660 - val_accuracy: 0.9726 - val_loss: 0.0981\n",
      "Epoch 8/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9821 - loss: 0.0661 - val_accuracy: 0.9724 - val_loss: 0.0969\n",
      "Epoch 9/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9824 - loss: 0.0643 - val_accuracy: 0.9726 - val_loss: 0.0971\n",
      "Epoch 10/10\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9837 - loss: 0.0600 - val_accuracy: 0.9731 - val_loss: 0.0940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1faab887310>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': [0.703819990158081, 0.8781399726867676, 0.89683997631073, 0.9065200090408325, 0.9137200117111206, 0.9186800122261047, 0.9235799908638, 0.9269000291824341, 0.9302399754524231, 0.9328399896621704, 0.9351000189781189, 0.9376199841499329, 0.9401800036430359, 0.9420199990272522, 0.9440600275993347, 0.9458000063896179, 0.9472000002861023, 0.9488199949264526, 0.9500799775123596, 0.9520400166511536, 0.9530799984931946, 0.9545599818229675, 0.9559800028800964, 0.9571599960327148, 0.9585999846458435, 0.9596800208091736, 0.9606599807739258, 0.9616600275039673, 0.9624199867248535, 0.9632999897003174, 0.9645799994468689, 0.9648200273513794, 0.9659799933433533, 0.9668599963188171, 0.9674999713897705, 0.968500018119812, 0.968779981136322, 0.9696199893951416, 0.9706000089645386, 0.9715999960899353, 0.9715399742126465, 0.9724599719047546, 0.9726799726486206, 0.9737799763679504, 0.9740599989891052, 0.97461998462677, 0.9754400253295898, 0.9761800169944763, 0.9765599966049194, 0.9768400192260742], 'loss': [1.214279055595398, 0.48878300189971924, 0.3806649148464203, 0.33560776710510254, 0.3078114688396454, 0.28768399357795715, 0.2718529999256134, 0.2587195634841919, 0.2471594512462616, 0.23685751855373383, 0.22772499918937683, 0.21898986399173737, 0.21122147142887115, 0.20391489565372467, 0.19733896851539612, 0.19079482555389404, 0.1850142627954483, 0.1791808009147644, 0.173889622092247, 0.1688205599784851, 0.1639498621225357, 0.15957856178283691, 0.15514753758907318, 0.1511116474866867, 0.14690494537353516, 0.14338088035583496, 0.13962528109550476, 0.13613595068454742, 0.1328403651714325, 0.12966932356357574, 0.12637078762054443, 0.12355642765760422, 0.12079238146543503, 0.11809063702821732, 0.11552927643060684, 0.11282467842102051, 0.11044204235076904, 0.1080671176314354, 0.10572241246700287, 0.10355284810066223, 0.10135012865066528, 0.09937173873186111, 0.09728259593248367, 0.09524096548557281, 0.0933179184794426, 0.09147753566503525, 0.08978993445634842, 0.08794915676116943, 0.08630857616662979, 0.0846766009926796], 'val_accuracy': [0.8741999864578247, 0.8996000289916992, 0.9104999899864197, 0.9175999760627747, 0.9215999841690063, 0.9272000193595886, 0.9311000108718872, 0.9333999752998352, 0.9361000061035156, 0.9373000264167786, 0.9395999908447266, 0.9430999755859375, 0.9442999958992004, 0.9473999738693237, 0.9474999904632568, 0.9495000243186951, 0.9527999758720398, 0.9531000256538391, 0.954200029373169, 0.9552000164985657, 0.9556000232696533, 0.9578999876976013, 0.9564999938011169, 0.9580000042915344, 0.958299994468689, 0.9587000012397766, 0.9599999785423279, 0.960099995136261, 0.9610000252723694, 0.9611999988555908, 0.9613000154495239, 0.9627000093460083, 0.9627000093460083, 0.9635000228881836, 0.9638000130653381, 0.9643999934196472, 0.9652000069618225, 0.9656000137329102, 0.9649999737739563, 0.9656000137329102, 0.96670001745224, 0.96670001745224, 0.967199981212616, 0.9678999781608582, 0.9675999879837036, 0.9675999879837036, 0.9679999947547913, 0.968999981880188, 0.9695000052452087, 0.9696000218391418], 'val_loss': [0.5644339919090271, 0.37907713651657104, 0.3223773241043091, 0.29444772005081177, 0.2760850787162781, 0.2583695948123932, 0.24693255126476288, 0.23620276153087616, 0.22690178453922272, 0.21948674321174622, 0.21103420853614807, 0.20434509217739105, 0.1990329623222351, 0.19282782077789307, 0.18812218308448792, 0.1832561492919922, 0.17934103310108185, 0.17540961503982544, 0.171402707695961, 0.16668272018432617, 0.1624794453382492, 0.15853270888328552, 0.15594777464866638, 0.152856707572937, 0.15096916258335114, 0.14620137214660645, 0.1448877602815628, 0.14132164418697357, 0.1397278606891632, 0.1375335305929184, 0.13710224628448486, 0.13351069390773773, 0.13290102779865265, 0.12963758409023285, 0.1274036318063736, 0.12739655375480652, 0.12436144798994064, 0.12365441024303436, 0.12378343194723129, 0.12019660323858261, 0.11927724629640579, 0.11775310337543488, 0.11598719656467438, 0.11433018743991852, 0.11335742473602295, 0.11260007321834564, 0.11162643879652023, 0.1105513796210289, 0.10929801315069199, 0.10807008296251297]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.703819990158081,\n",
       "  0.8781399726867676,\n",
       "  0.89683997631073,\n",
       "  0.9065200090408325,\n",
       "  0.9137200117111206,\n",
       "  0.9186800122261047,\n",
       "  0.9235799908638,\n",
       "  0.9269000291824341,\n",
       "  0.9302399754524231,\n",
       "  0.9328399896621704,\n",
       "  0.9351000189781189,\n",
       "  0.9376199841499329,\n",
       "  0.9401800036430359,\n",
       "  0.9420199990272522,\n",
       "  0.9440600275993347,\n",
       "  0.9458000063896179,\n",
       "  0.9472000002861023,\n",
       "  0.9488199949264526,\n",
       "  0.9500799775123596,\n",
       "  0.9520400166511536,\n",
       "  0.9530799984931946,\n",
       "  0.9545599818229675,\n",
       "  0.9559800028800964,\n",
       "  0.9571599960327148,\n",
       "  0.9585999846458435,\n",
       "  0.9596800208091736,\n",
       "  0.9606599807739258,\n",
       "  0.9616600275039673,\n",
       "  0.9624199867248535,\n",
       "  0.9632999897003174,\n",
       "  0.9645799994468689,\n",
       "  0.9648200273513794,\n",
       "  0.9659799933433533,\n",
       "  0.9668599963188171,\n",
       "  0.9674999713897705,\n",
       "  0.968500018119812,\n",
       "  0.968779981136322,\n",
       "  0.9696199893951416,\n",
       "  0.9706000089645386,\n",
       "  0.9715999960899353,\n",
       "  0.9715399742126465,\n",
       "  0.9724599719047546,\n",
       "  0.9726799726486206,\n",
       "  0.9737799763679504,\n",
       "  0.9740599989891052,\n",
       "  0.97461998462677,\n",
       "  0.9754400253295898,\n",
       "  0.9761800169944763,\n",
       "  0.9765599966049194,\n",
       "  0.9768400192260742],\n",
       " 'loss': [1.214279055595398,\n",
       "  0.48878300189971924,\n",
       "  0.3806649148464203,\n",
       "  0.33560776710510254,\n",
       "  0.3078114688396454,\n",
       "  0.28768399357795715,\n",
       "  0.2718529999256134,\n",
       "  0.2587195634841919,\n",
       "  0.2471594512462616,\n",
       "  0.23685751855373383,\n",
       "  0.22772499918937683,\n",
       "  0.21898986399173737,\n",
       "  0.21122147142887115,\n",
       "  0.20391489565372467,\n",
       "  0.19733896851539612,\n",
       "  0.19079482555389404,\n",
       "  0.1850142627954483,\n",
       "  0.1791808009147644,\n",
       "  0.173889622092247,\n",
       "  0.1688205599784851,\n",
       "  0.1639498621225357,\n",
       "  0.15957856178283691,\n",
       "  0.15514753758907318,\n",
       "  0.1511116474866867,\n",
       "  0.14690494537353516,\n",
       "  0.14338088035583496,\n",
       "  0.13962528109550476,\n",
       "  0.13613595068454742,\n",
       "  0.1328403651714325,\n",
       "  0.12966932356357574,\n",
       "  0.12637078762054443,\n",
       "  0.12355642765760422,\n",
       "  0.12079238146543503,\n",
       "  0.11809063702821732,\n",
       "  0.11552927643060684,\n",
       "  0.11282467842102051,\n",
       "  0.11044204235076904,\n",
       "  0.1080671176314354,\n",
       "  0.10572241246700287,\n",
       "  0.10355284810066223,\n",
       "  0.10135012865066528,\n",
       "  0.09937173873186111,\n",
       "  0.09728259593248367,\n",
       "  0.09524096548557281,\n",
       "  0.0933179184794426,\n",
       "  0.09147753566503525,\n",
       "  0.08978993445634842,\n",
       "  0.08794915676116943,\n",
       "  0.08630857616662979,\n",
       "  0.0846766009926796],\n",
       " 'val_accuracy': [0.8741999864578247,\n",
       "  0.8996000289916992,\n",
       "  0.9104999899864197,\n",
       "  0.9175999760627747,\n",
       "  0.9215999841690063,\n",
       "  0.9272000193595886,\n",
       "  0.9311000108718872,\n",
       "  0.9333999752998352,\n",
       "  0.9361000061035156,\n",
       "  0.9373000264167786,\n",
       "  0.9395999908447266,\n",
       "  0.9430999755859375,\n",
       "  0.9442999958992004,\n",
       "  0.9473999738693237,\n",
       "  0.9474999904632568,\n",
       "  0.9495000243186951,\n",
       "  0.9527999758720398,\n",
       "  0.9531000256538391,\n",
       "  0.954200029373169,\n",
       "  0.9552000164985657,\n",
       "  0.9556000232696533,\n",
       "  0.9578999876976013,\n",
       "  0.9564999938011169,\n",
       "  0.9580000042915344,\n",
       "  0.958299994468689,\n",
       "  0.9587000012397766,\n",
       "  0.9599999785423279,\n",
       "  0.960099995136261,\n",
       "  0.9610000252723694,\n",
       "  0.9611999988555908,\n",
       "  0.9613000154495239,\n",
       "  0.9627000093460083,\n",
       "  0.9627000093460083,\n",
       "  0.9635000228881836,\n",
       "  0.9638000130653381,\n",
       "  0.9643999934196472,\n",
       "  0.9652000069618225,\n",
       "  0.9656000137329102,\n",
       "  0.9649999737739563,\n",
       "  0.9656000137329102,\n",
       "  0.96670001745224,\n",
       "  0.96670001745224,\n",
       "  0.967199981212616,\n",
       "  0.9678999781608582,\n",
       "  0.9675999879837036,\n",
       "  0.9675999879837036,\n",
       "  0.9679999947547913,\n",
       "  0.968999981880188,\n",
       "  0.9695000052452087,\n",
       "  0.9696000218391418],\n",
       " 'val_loss': [0.5644339919090271,\n",
       "  0.37907713651657104,\n",
       "  0.3223773241043091,\n",
       "  0.29444772005081177,\n",
       "  0.2760850787162781,\n",
       "  0.2583695948123932,\n",
       "  0.24693255126476288,\n",
       "  0.23620276153087616,\n",
       "  0.22690178453922272,\n",
       "  0.21948674321174622,\n",
       "  0.21103420853614807,\n",
       "  0.20434509217739105,\n",
       "  0.1990329623222351,\n",
       "  0.19282782077789307,\n",
       "  0.18812218308448792,\n",
       "  0.1832561492919922,\n",
       "  0.17934103310108185,\n",
       "  0.17540961503982544,\n",
       "  0.171402707695961,\n",
       "  0.16668272018432617,\n",
       "  0.1624794453382492,\n",
       "  0.15853270888328552,\n",
       "  0.15594777464866638,\n",
       "  0.152856707572937,\n",
       "  0.15096916258335114,\n",
       "  0.14620137214660645,\n",
       "  0.1448877602815628,\n",
       "  0.14132164418697357,\n",
       "  0.1397278606891632,\n",
       "  0.1375335305929184,\n",
       "  0.13710224628448486,\n",
       "  0.13351069390773773,\n",
       "  0.13290102779865265,\n",
       "  0.12963758409023285,\n",
       "  0.1274036318063736,\n",
       "  0.12739655375480652,\n",
       "  0.12436144798994064,\n",
       "  0.12365441024303436,\n",
       "  0.12378343194723129,\n",
       "  0.12019660323858261,\n",
       "  0.11927724629640579,\n",
       "  0.11775310337543488,\n",
       "  0.11598719656467438,\n",
       "  0.11433018743991852,\n",
       "  0.11335742473602295,\n",
       "  0.11260007321834564,\n",
       "  0.11162643879652023,\n",
       "  0.1105513796210289,\n",
       "  0.10929801315069199,\n",
       "  0.10807008296251297]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['accuracy', 'loss', 'val_accuracy', 'val_loss'])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.70382</td>\n",
       "      <td>1.214279</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.564434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.87814</td>\n",
       "      <td>0.488783</td>\n",
       "      <td>0.8996</td>\n",
       "      <td>0.379077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.89684</td>\n",
       "      <td>0.380665</td>\n",
       "      <td>0.9105</td>\n",
       "      <td>0.322377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.90652</td>\n",
       "      <td>0.335608</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.294448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.91372</td>\n",
       "      <td>0.307811</td>\n",
       "      <td>0.9216</td>\n",
       "      <td>0.276085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.91868</td>\n",
       "      <td>0.287684</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.258370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.92358</td>\n",
       "      <td>0.271853</td>\n",
       "      <td>0.9311</td>\n",
       "      <td>0.246933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.92690</td>\n",
       "      <td>0.258720</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.236203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.93024</td>\n",
       "      <td>0.247159</td>\n",
       "      <td>0.9361</td>\n",
       "      <td>0.226902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.93284</td>\n",
       "      <td>0.236858</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.219487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.93510</td>\n",
       "      <td>0.227725</td>\n",
       "      <td>0.9396</td>\n",
       "      <td>0.211034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.93762</td>\n",
       "      <td>0.218990</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>0.204345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.94018</td>\n",
       "      <td>0.211221</td>\n",
       "      <td>0.9443</td>\n",
       "      <td>0.199033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.94202</td>\n",
       "      <td>0.203915</td>\n",
       "      <td>0.9474</td>\n",
       "      <td>0.192828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.94406</td>\n",
       "      <td>0.197339</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.188122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.94580</td>\n",
       "      <td>0.190795</td>\n",
       "      <td>0.9495</td>\n",
       "      <td>0.183256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.94720</td>\n",
       "      <td>0.185014</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.179341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.94882</td>\n",
       "      <td>0.179181</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.175410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.95008</td>\n",
       "      <td>0.173890</td>\n",
       "      <td>0.9542</td>\n",
       "      <td>0.171403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.95204</td>\n",
       "      <td>0.168821</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.166683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.95308</td>\n",
       "      <td>0.163950</td>\n",
       "      <td>0.9556</td>\n",
       "      <td>0.162479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.95456</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.158533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.95598</td>\n",
       "      <td>0.155148</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.155948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.95716</td>\n",
       "      <td>0.151112</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>0.152857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.95860</td>\n",
       "      <td>0.146905</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.150969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.95968</td>\n",
       "      <td>0.143381</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.146201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.96066</td>\n",
       "      <td>0.139625</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0.144888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.96166</td>\n",
       "      <td>0.136136</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.141322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.96242</td>\n",
       "      <td>0.132840</td>\n",
       "      <td>0.9610</td>\n",
       "      <td>0.139728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.96330</td>\n",
       "      <td>0.129669</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>0.137534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.96458</td>\n",
       "      <td>0.126371</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>0.137102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.96482</td>\n",
       "      <td>0.123556</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.133511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.96598</td>\n",
       "      <td>0.120792</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>0.132901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.96686</td>\n",
       "      <td>0.118091</td>\n",
       "      <td>0.9635</td>\n",
       "      <td>0.129638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.96750</td>\n",
       "      <td>0.115529</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.127404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.96850</td>\n",
       "      <td>0.112825</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.127397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.96878</td>\n",
       "      <td>0.110442</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.124361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.96962</td>\n",
       "      <td>0.108067</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.123654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.97060</td>\n",
       "      <td>0.105722</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.123783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.97160</td>\n",
       "      <td>0.103553</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.120197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.97154</td>\n",
       "      <td>0.101350</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.119277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.97246</td>\n",
       "      <td>0.099372</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.117753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.97268</td>\n",
       "      <td>0.097283</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.115987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.97378</td>\n",
       "      <td>0.095241</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.114330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.97406</td>\n",
       "      <td>0.093318</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.113357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.97462</td>\n",
       "      <td>0.091478</td>\n",
       "      <td>0.9676</td>\n",
       "      <td>0.112600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.97544</td>\n",
       "      <td>0.089790</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.111626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.97618</td>\n",
       "      <td>0.087949</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.110551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.97656</td>\n",
       "      <td>0.086309</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.109298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.97684</td>\n",
       "      <td>0.084677</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.108070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      loss  val_accuracy  val_loss\n",
       "0    0.70382  1.214279        0.8742  0.564434\n",
       "1    0.87814  0.488783        0.8996  0.379077\n",
       "2    0.89684  0.380665        0.9105  0.322377\n",
       "3    0.90652  0.335608        0.9176  0.294448\n",
       "4    0.91372  0.307811        0.9216  0.276085\n",
       "5    0.91868  0.287684        0.9272  0.258370\n",
       "6    0.92358  0.271853        0.9311  0.246933\n",
       "7    0.92690  0.258720        0.9334  0.236203\n",
       "8    0.93024  0.247159        0.9361  0.226902\n",
       "9    0.93284  0.236858        0.9373  0.219487\n",
       "10   0.93510  0.227725        0.9396  0.211034\n",
       "11   0.93762  0.218990        0.9431  0.204345\n",
       "12   0.94018  0.211221        0.9443  0.199033\n",
       "13   0.94202  0.203915        0.9474  0.192828\n",
       "14   0.94406  0.197339        0.9475  0.188122\n",
       "15   0.94580  0.190795        0.9495  0.183256\n",
       "16   0.94720  0.185014        0.9528  0.179341\n",
       "17   0.94882  0.179181        0.9531  0.175410\n",
       "18   0.95008  0.173890        0.9542  0.171403\n",
       "19   0.95204  0.168821        0.9552  0.166683\n",
       "20   0.95308  0.163950        0.9556  0.162479\n",
       "21   0.95456  0.159579        0.9579  0.158533\n",
       "22   0.95598  0.155148        0.9565  0.155948\n",
       "23   0.95716  0.151112        0.9580  0.152857\n",
       "24   0.95860  0.146905        0.9583  0.150969\n",
       "25   0.95968  0.143381        0.9587  0.146201\n",
       "26   0.96066  0.139625        0.9600  0.144888\n",
       "27   0.96166  0.136136        0.9601  0.141322\n",
       "28   0.96242  0.132840        0.9610  0.139728\n",
       "29   0.96330  0.129669        0.9612  0.137534\n",
       "30   0.96458  0.126371        0.9613  0.137102\n",
       "31   0.96482  0.123556        0.9627  0.133511\n",
       "32   0.96598  0.120792        0.9627  0.132901\n",
       "33   0.96686  0.118091        0.9635  0.129638\n",
       "34   0.96750  0.115529        0.9638  0.127404\n",
       "35   0.96850  0.112825        0.9644  0.127397\n",
       "36   0.96878  0.110442        0.9652  0.124361\n",
       "37   0.96962  0.108067        0.9656  0.123654\n",
       "38   0.97060  0.105722        0.9650  0.123783\n",
       "39   0.97160  0.103553        0.9656  0.120197\n",
       "40   0.97154  0.101350        0.9667  0.119277\n",
       "41   0.97246  0.099372        0.9667  0.117753\n",
       "42   0.97268  0.097283        0.9672  0.115987\n",
       "43   0.97378  0.095241        0.9679  0.114330\n",
       "44   0.97406  0.093318        0.9676  0.113357\n",
       "45   0.97462  0.091478        0.9676  0.112600\n",
       "46   0.97544  0.089790        0.9680  0.111626\n",
       "47   0.97618  0.087949        0.9690  0.110551\n",
       "48   0.97656  0.086309        0.9695  0.109298\n",
       "49   0.97684  0.084677        0.9696  0.108070"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9690 - loss: 0.1033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0885404571890831, 0.9735999703407288]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_15952\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.003, 0.   , 0.   , 0.   , 0.997, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "np.round(predictions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.21762479e-06, 6.92281219e-07, 4.16520837e-04, 2.69858027e-03,\n",
       "        6.43590212e-08, 2.23180086e-05, 1.05637596e-10, 9.96821284e-01,\n",
       "        6.27485269e-06, 2.99583280e-05]], dtype=float32)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(7)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diego Nuñez\\AppData\\Local\\Temp\\ipykernel_15952\\4029188365.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 968,    0,    0,    1,    2,    0,    3,    1,    3,    2],\n",
       "       [   0, 1123,    2,    1,    0,    1,    3,    0,    5,    0],\n",
       "       [   5,    2, 1006,    4,    3,    0,    2,    5,    5,    0],\n",
       "       [   0,    0,    4,  989,    0,    4,    0,    5,    7,    1],\n",
       "       [   2,    0,    4,    1,  950,    0,    4,    4,    2,   15],\n",
       "       [   3,    0,    0,    6,    1,  867,    6,    1,    6,    2],\n",
       "       [   7,    3,    3,    1,    3,    7,  931,    0,    3,    0],\n",
       "       [   1,    8,   11,    6,    0,    0,    0,  997,    0,    5],\n",
       "       [   3,    2,    3,    8,    4,    5,    5,    2,  941,    1],\n",
       "       [   5,    5,    0,    9,   11,    3,    0,    7,    5,  964]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98       980\n",
      "         1.0       0.98      0.99      0.99      1135\n",
      "         2.0       0.97      0.97      0.97      1032\n",
      "         3.0       0.96      0.98      0.97      1010\n",
      "         4.0       0.98      0.97      0.97       982\n",
      "         5.0       0.98      0.97      0.97       892\n",
      "         6.0       0.98      0.97      0.97       958\n",
      "         7.0       0.98      0.97      0.97      1028\n",
      "         8.0       0.96      0.97      0.96       974\n",
      "         9.0       0.97      0.96      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2795 - val_loss: 19.6548\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.0314 - val_loss: 1.7984\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 6.0593 - val_loss: 0.5507\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4727 - val_loss: 0.4300\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4325 - val_loss: 0.4100\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3963 - val_loss: 0.3951\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4026 - val_loss: 0.3949\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3780 - val_loss: 0.3889\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3629 - val_loss: 0.3881\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3769 - val_loss: 0.3812\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3771 - val_loss: 0.3939\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3590 - val_loss: 0.3795\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3579 - val_loss: 0.3875\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3513 - val_loss: 0.3841\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3448 - val_loss: 0.3784\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3344 - val_loss: 0.3775\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3631 - val_loss: 0.3827\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3411 - val_loss: 0.3751\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3537 - val_loss: 0.3775\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3426 - val_loss: 0.3782\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │           \u001b[38;5;34m270\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m31\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">303</span> (1.19 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m303\u001b[0m (1.19 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">301</span> (1.18 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m301\u001b[0m (1.18 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3689\n",
      "0.3622754216194153\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.3760054],\n",
       "       [1.2083163],\n",
       "       [2.072228 ],\n",
       "       [0.6865401],\n",
       "       [1.1529279]], dtype=float32)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "numpy() is only available when eager execution is enabled.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[118]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m checkpoint_cb = keras.callbacks.ModelCheckpoint(\u001b[33m\"\u001b[39m\u001b[33mcallback_model.h5\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Diego Nuñez\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:171\u001b[39m, in \u001b[36mconvert_to_numpy\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, tf.RaggedTensor):\n\u001b[32m    170\u001b[39m     x = x.to_tensor()\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(x)\n",
      "\u001b[31mNotImplementedError\u001b[39m: numpy() is only available when eager execution is enabled."
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m early_stopping_cb = keras.callbacks.EarlyStopping(patience=\u001b[32m3\u001b[39m)\n\u001b[32m      2\u001b[39m history = model.fit(X_train,\n\u001b[32m      3\u001b[39m                    y_train,\n\u001b[32m      4\u001b[39m                    epochs=\u001b[32m50\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m                    validation_data = (\u001b[43mX_valid\u001b[49m, y_valid),\n\u001b[32m      6\u001b[39m                    callbacks = [early_stopping_cb, checkpoint_cb])\n",
      "\u001b[31mNameError\u001b[39m: name 'X_valid' is not defined"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
